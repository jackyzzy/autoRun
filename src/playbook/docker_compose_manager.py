"""
Docker Composeç®¡ç†å™¨
å¤„ç†å¤šcomposeæ–‡ä»¶å’Œé€‰æ‹©æ€§æœåŠ¡éƒ¨ç½²
"""

import os
import yaml
import logging
from typing import Dict, List, Optional, Any, Set
from pathlib import Path
import tempfile
import shutil

from .node_manager import NodeManager
from .scenario_manager import ServiceDeployment
from .docker_container_service import DockerContainerService


class DockerComposeService:
    """Docker ComposeæœåŠ¡å®šä¹‰"""
    
    def __init__(self, name: str, definition: Dict[str, Any]):
        self.name = name
        self.definition = definition
        self.depends_on = definition.get('depends_on', [])
        
    def to_dict(self) -> Dict[str, Any]:
        return {self.name: self.definition}


class DockerComposeFile:
    """Docker Composeæ–‡ä»¶ç®¡ç†"""
    
    def __init__(self, file_path: str):
        self.file_path = Path(file_path)
        self.services: Dict[str, DockerComposeService] = {}
        self.compose_data: Dict[str, Any] = {}
        self.load()
        
    def load(self):
        """åŠ è½½composeæ–‡ä»¶"""
        if not self.file_path.exists():
            raise FileNotFoundError(f"Docker Compose file not found: {self.file_path}")
            
        with open(self.file_path, 'r', encoding='utf-8') as f:
            self.compose_data = yaml.safe_load(f)
            
        # è§£ææœåŠ¡å®šä¹‰
        services_data = self.compose_data.get('services', {})
        for service_name, service_def in services_data.items():
            self.services[service_name] = DockerComposeService(service_name, service_def)
    
    def get_service_names(self) -> List[str]:
        """è·å–æ‰€æœ‰æœåŠ¡åç§°"""
        return list(self.services.keys())
    
    def has_service(self, service_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡å®šæœåŠ¡"""
        return service_name in self.services
    
    def create_filtered_compose(self, service_names: List[str], output_path: str) -> bool:
        """åˆ›å»ºåŒ…å«æŒ‡å®šæœåŠ¡çš„è¿‡æ»¤ç‰ˆæœ¬composeæ–‡ä»¶"""
        try:
            # è¿‡æ»¤æœåŠ¡
            filtered_services = {}
            for service_name in service_names:
                if service_name in self.services:
                    filtered_services.update(self.services[service_name].to_dict())
            
            if not filtered_services:
                return False
                
            # åˆ›å»ºæ–°çš„composeæ•°æ®
            filtered_compose = self.compose_data.copy()
            filtered_compose['services'] = filtered_services
            
            # å†™å…¥æ–‡ä»¶
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                yaml.dump(filtered_compose, f, default_flow_style=False, allow_unicode=True)
            
            return True
            
        except Exception as e:
            logging.error(f"Failed to create filtered compose file: {e}")
            return False


class DockerComposeManager:
    """Docker Composeç®¡ç†å™¨"""
    
    def __init__(self, node_manager: NodeManager):
        self.logger = logging.getLogger("playbook.docker_compose_manager")
        self.node_manager = node_manager
        self.compose_files: Dict[str, DockerComposeFile] = {}
        self.container_service = DockerContainerService(node_manager)
        
    def discover_compose_files(self, scenario_path: Path) -> List[str]:
        """å‘ç°åœºæ™¯ç›®å½•ä¸‹çš„æ‰€æœ‰composeæ–‡ä»¶"""
        compose_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰docker-compose*.ymlå’Œdocker-compose*.yamlæ–‡ä»¶
        patterns = ["docker-compose*.yml", "docker-compose*.yaml"]
        
        for pattern in patterns:
            for file_path in scenario_path.glob(pattern):
                compose_files.append(str(file_path))
                
        self.logger.info(f"Discovered {len(compose_files)} compose files in {scenario_path}")
        return sorted(compose_files)
    
    def load_compose_file(self, file_path: str) -> DockerComposeFile:
        """åŠ è½½composeæ–‡ä»¶"""
        if file_path not in self.compose_files:
            self.compose_files[file_path] = DockerComposeFile(file_path)
        return self.compose_files[file_path]
    
    def validate_service_deployment(self, scenario_path: Path, 
                                  services: List[ServiceDeployment]) -> Dict[str, List[str]]:
        """éªŒè¯æœåŠ¡éƒ¨ç½²é…ç½®"""
        results = {
            'valid_services': [],
            'invalid_services': [],
            'missing_files': [],
            'missing_nodes': []
        }
        
        # å‘ç°å¯ç”¨çš„composeæ–‡ä»¶
        available_files = self.discover_compose_files(scenario_path)
        
        # è·å–å¯ç”¨èŠ‚ç‚¹
        available_nodes = {node.name for node in self.node_manager.get_nodes()}
        
        for service in services:
            compose_file_path = scenario_path / service.compose_file
            
            # æ£€æŸ¥composeæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not compose_file_path.exists():
                results['missing_files'].append(f"{service.name}: {service.compose_file}")
                continue
            
            try:
                # åŠ è½½composeæ–‡ä»¶
                compose_file = self.load_compose_file(str(compose_file_path))
                
                # æ£€æŸ¥æœåŠ¡æ˜¯å¦å­˜åœ¨äºcomposeæ–‡ä»¶ä¸­
                if not compose_file.has_service(service.name):
                    results['invalid_services'].append(
                        f"{service.name}: not found in {service.compose_file}"
                    )
                    continue
                
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
                missing_nodes = set(service.nodes) - available_nodes
                if missing_nodes:
                    results['missing_nodes'].extend([
                        f"{service.name}: nodes {list(missing_nodes)} not available"
                    ])
                    continue
                
                results['valid_services'].append(service.name)
                
            except Exception as e:
                results['invalid_services'].append(f"{service.name}: {str(e)}")
        
        return results
    
    def deploy_service(self, scenario_path: Path, service: ServiceDeployment,
                      node_name: str, timeout: int = 300, is_retry: bool = False) -> bool:
        """åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šéƒ¨ç½²æœåŠ¡"""
        try:
            compose_file_path = scenario_path / service.compose_file
            compose_file = self.load_compose_file(str(compose_file_path))
            
            # æ£€æŸ¥æœåŠ¡æ˜¯å¦å­˜åœ¨
            if not compose_file.has_service(service.name):
                self.logger.error(f"Service {service.name} not found in {service.compose_file}")
                return False
            
            # è·å–èŠ‚ç‚¹
            node = self.node_manager.get_node(node_name)
            if not node:
                self.logger.error(f"Node {node_name} not found")
                return False
            
            # ç›´æ¥ä¸Šä¼ å®Œæ•´çš„composeæ–‡ä»¶
            remote_compose_path = f"{node.docker_compose_path}/{service.compose_file}"
            # å¦‚æœæ˜¯é‡è¯•ï¼Œå¯ä»¥è·³è¿‡ç›¸åŒæ–‡ä»¶çš„ä¸Šä¼ ï¼›é¦–æ¬¡éƒ¨ç½²æ€»æ˜¯å¼ºåˆ¶ä¸Šä¼ 
            force_upload = not is_retry
            upload_success = self._upload_compose_file_with_retry(
                str(compose_file_path), remote_compose_path, node_name, retries=2, force_upload=force_upload
            )

            if not upload_success:
                self.logger.error(f"Failed to upload compose file to {node_name}")
                return False

            # åœ¨èŠ‚ç‚¹ä¸Šå¯åŠ¨æœåŠ¡ - ä½¿ç”¨é€‚é…å™¨æ„å»ºå‘½ä»¤
            compose_cmd = self.node_manager.build_compose_command(
                node_name=node_name,
                command_type="up",
                file=service.compose_file,
                services=[service.name]
            )

            full_cmd = f"cd {node.docker_compose_path} && {compose_cmd.full_cmd}"
            self.logger.info(f"Deploying {service.name} on {node_name} using {compose_cmd.version.value} with command: {compose_cmd.full_cmd}")

            results = self.node_manager.execute_command(full_cmd, [node_name], timeout=timeout)

            node_result = results.get(node_name)
            if node_result and node_result[0] == 0:
                self.logger.info(f"Successfully deployed {service.name} on {node_name}")
                return True
            else:
                # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                exit_code = node_result[0] if node_result else "unknown"
                stdout_data = node_result[1] if node_result and len(node_result) > 1 else ""
                stderr_data = node_result[2] if node_result and len(node_result) > 2 else ""

                error_parts = [f"Failed to deploy {service.name} on {node_name} (exit code: {exit_code})"]

                if stderr_data.strip():
                    error_parts.append(f"stderr: {stderr_data.strip()}")
                if stdout_data.strip():
                    error_parts.append(f"stdout: {stdout_data.strip()}")

                error_msg = "; ".join(error_parts)
                self.logger.error(error_msg)
                return False
                
        except Exception as e:
            self.logger.error(f"Error deploying service {service.name} on {node_name}: {e}")
            return False

    def _upload_compose_file_with_retry(self, local_path: str, remote_path: str, node_name: str, retries: int = 2, force_upload: bool = True) -> bool:
        """ğŸ”’ å¸¦é‡è¯•å’Œå¹¶å‘ä¿æŠ¤çš„composeæ–‡ä»¶ä¸Šä¼ """
        import time
        import os
        import hashlib

        # è®¡ç®—æœ¬åœ°æ–‡ä»¶çš„å“ˆå¸Œå€¼ï¼Œç”¨äºéªŒè¯
        try:
            with open(local_path, 'rb') as f:
                local_hash = hashlib.md5(f.read()).hexdigest()
            local_size = os.path.getsize(local_path)
        except Exception as e:
            self.logger.error(f"Failed to read local file {local_path}: {e}")
            return False

        # åªåœ¨éå¼ºåˆ¶ä¸Šä¼ æ—¶æ£€æŸ¥è¿œç¨‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”ç›¸åŒ
        if not force_upload:
            try:
                check_cmd = f"test -f {remote_path} && md5sum {remote_path} | cut -d' ' -f1"
                result = self.node_manager.execute_command(check_cmd, [node_name], timeout=10)
                node_result = result.get(node_name)

                if node_result and node_result[0] == 0:
                    remote_hash = node_result[1].strip()
                    if remote_hash == local_hash:
                        self.logger.debug(f"Compose file already exists and matches on {node_name}, skipping upload")
                        return True
                    else:
                        self.logger.debug(f"Compose file exists but differs on {node_name}, will overwrite")
            except Exception as e:
                self.logger.debug(f"Could not check existing file: {e}")
        else:
            self.logger.debug(f"Force upload enabled, will overwrite any existing file")

        # æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸åŒï¼Œéœ€è¦ä¸Šä¼ 
        for attempt in range(retries + 1):
            try:
                upload_result = self.node_manager.upload_file(local_path, remote_path, [node_name])
                success = upload_result.get(node_name, False)

                if success:
                    # éªŒè¯ä¸Šä¼ åçš„æ–‡ä»¶
                    verify_cmd = f"md5sum {remote_path} | cut -d' ' -f1"
                    verify_result = self.node_manager.execute_command(verify_cmd, [node_name], timeout=10)
                    node_verify = verify_result.get(node_name)

                    if node_verify and node_verify[0] == 0:
                        uploaded_hash = node_verify[1].strip()
                        if uploaded_hash == local_hash:
                            if attempt > 0:
                                self.logger.info(f"File upload succeeded on attempt {attempt + 1}")
                            return True
                        else:
                            self.logger.warning(f"Upload verification failed: hash mismatch")
                            success = False

                if not success:
                    if attempt < retries:
                        self.logger.warning(f"File upload failed (attempt {attempt + 1}/{retries + 1}), retrying in 1 second...")
                        time.sleep(1)
                    else:
                        self.logger.error(f"File upload failed after {retries + 1} attempts")

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯è§£é‡Šå™¨å…³é—­å¯¼è‡´çš„é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™å¿«é€Ÿå¤±è´¥
                if "interpreter shutdown" in str(e).lower():
                    self.logger.warning(f"Interpreter shutting down, aborting file upload")
                    return False

                if attempt < retries:
                    self.logger.warning(f"File upload error (attempt {attempt + 1}/{retries + 1}): {e}, retrying...")
                    time.sleep(1)
                else:
                    self.logger.error(f"File upload error after {retries + 1} attempts: {e}")

        return False

    def stop_service(self, scenario_path: Path, service: ServiceDeployment,
                    node_name: str, timeout: int = 120) -> bool:
        """åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šåœæ­¢æœåŠ¡"""
        try:
            node = self.node_manager.get_node(node_name)
            if not node:
                self.logger.error(f"Node {node_name} not found")
                return False
            
            # åœæ­¢æœåŠ¡ - ä½¿ç”¨é€‚é…å™¨æ„å»ºå‘½ä»¤
            stop_cmd = self.node_manager.build_compose_command(
                node_name=node_name,
                command_type="stop",
                file=service.compose_file,
                services=[service.name]
            )

            rm_cmd = self.node_manager.build_compose_command(
                node_name=node_name,
                command_type="rm",
                file=service.compose_file,
                services=[service.name]
            )

            full_cmd = f"cd {node.docker_compose_path} && {stop_cmd.full_cmd} && {rm_cmd.full_cmd}"
            results = self.node_manager.execute_command(full_cmd, [node_name], timeout=timeout)
            
            node_result = results.get(node_name)
            if node_result and node_result[0] == 0:
                self.logger.info(f"Successfully stopped {service.name} on {node_name}")
                return True
            else:
                error_msg = node_result[2] if node_result else "Unknown error"
                self.logger.warning(f"Failed to stop {service.name} on {node_name}: {error_msg}")
                # ä¸è¿”å›Falseï¼Œå…è®¸ç»§ç»­æ¸…ç†
                return True
                
        except Exception as e:
            self.logger.error(f"Error stopping service {service.name} on {node_name}: {e}")
            return False
    
    def get_service_status(self, service_name: str, node_name: str) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„å®¹å™¨æœåŠ¡æŸ¥æ‰¾å®¹å™¨ï¼ˆåŒ…å«åœæ­¢çš„å®¹å™¨ï¼‰
            result = self.container_service.find_containers_for_service(
                service_name=service_name,
                node_name=node_name,
                include_stopped=True  # docker_compose_manager éœ€è¦æŸ¥çœ‹æ‰€æœ‰å®¹å™¨çŠ¶æ€
            )
            
            if not result.success:
                return {
                    'node': node_name,
                    'service': service_name,
                    'running': False,
                    'error': result.error or "Container not found with any matching strategy"
                }
            
            # æ£€æŸ¥è¿è¡Œä¸­çš„å®¹å™¨
            running_containers = result.get_running_containers()
            has_running = len(running_containers) > 0
            
            # æ„å»ºè¿”å›æ ¼å¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            status_info = {
                'node': node_name,
                'service': service_name,
                'running': has_running,
                'containers': [],
                'strategy': result.strategy_used,
                'details': f"Found {len(result.containers)} container(s) using {result.strategy_used}"
            }
            
            # è½¬æ¢å®¹å™¨ä¿¡æ¯ä¸ºæ—§æ ¼å¼
            for container in result.containers:
                status_info['containers'].append({
                    'name': container.name,
                    'status': container.status,
                    'ports': container.ports,
                    'running': container.is_running()
                })
            
            self.logger.info(f"æœåŠ¡çŠ¶æ€æ£€æŸ¥å®Œæˆ - {service_name}@{node_name}: {len(result.containers)}ä¸ªå®¹å™¨, {len(running_containers)}ä¸ªè¿è¡Œä¸­, ç­–ç•¥: {result.strategy_used}")
            
            return status_info
                
        except Exception as e:
            self.logger.error(f"è·å–æœåŠ¡çŠ¶æ€å¤±è´¥ - {service_name}@{node_name}: {e}")
            return {
                'node': node_name,
                'service': service_name,
                'running': False,
                'error': str(e)
            }
    
    def cleanup_node_compose_files(self, node_names: List[str]):
        """æ¸…ç†èŠ‚ç‚¹ä¸Šçš„composeæ–‡ä»¶"""
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹æ„å»ºdownå‘½ä»¤ï¼ˆå‡è®¾æ‰€æœ‰èŠ‚ç‚¹ç‰ˆæœ¬ç›¸åŒï¼Œæˆ–è€…ä½¿ç”¨é€šç”¨å‘½ä»¤ï¼‰
        if node_names:
            first_node = node_names[0]
            try:
                down_cmd = self.node_manager.build_compose_command(
                    node_name=first_node,
                    command_type="down",
                    file="docker-compose.yml"  # ä½¿ç”¨é€šç”¨æ–‡ä»¶å
                )
                cleanup_commands = [
                    down_cmd.full_cmd.replace("docker-compose.yml", "*compose*.yml") + " --remove-orphans || true",
                    "docker system prune -f"
                ]
            except Exception as e:
                self.logger.warning(f"Failed to build adaptive down command, using default: {e}")
                cleanup_commands = [
                    "docker compose down --remove-orphans || docker-compose down --remove-orphans || true",
                    "docker system prune -f"
                ]
        else:
            cleanup_commands = [
                "docker compose down --remove-orphans || docker-compose down --remove-orphans || true",
                "docker system prune -f"
            ]
        
        for cmd in cleanup_commands:
            try:
                results = self.node_manager.execute_command(cmd, node_names, timeout=120)
                success_count = sum(1 for r in results.values() if r[0] == 0)
                self.logger.info(f"Cleanup command '{cmd}' executed on {success_count}/{len(node_names)} nodes")
            except Exception as e:
                self.logger.warning(f"Cleanup command failed: {e}")