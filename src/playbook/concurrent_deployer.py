"""
ğŸš€ å¹¶å‘æœåŠ¡éƒ¨ç½²å™¨ - åŸºäºä¾èµ–å…³ç³»çš„æ™ºèƒ½å¹¶å‘éƒ¨ç½²ç³»ç»Ÿ

ğŸ“Š æ ¸å¿ƒç‰¹æ€§ï¼š
1. æ‰¹æ¬¡é—´ä¸²è¡Œï¼Œæ‰¹æ¬¡å†…å¹¶å‘ - ç¡®ä¿ä¾èµ–å…³ç³»æ­£ç¡®å¤„ç†
2. åŸºäºä¿¡å·é‡çš„å¹¶å‘æ§åˆ¶ - é˜²æ­¢èµ„æºäº‰æŠ¢å’Œç³»ç»Ÿè¿‡è½½
3. æ™ºèƒ½é‡è¯•æœºåˆ¶ - åªé‡è¯•å¤±è´¥çš„æœåŠ¡ï¼Œä¸å½±å“å·²æˆåŠŸçš„æœåŠ¡
4. å®æ—¶è¿›åº¦è·Ÿè¸ª - æä¾›è¯¦ç»†çš„éƒ¨ç½²çŠ¶æ€å’Œæ—¶é—´ä¿¡æ¯
5. å¼‚æ­¥å¥åº·æ£€æŸ¥ - å¹¶å‘ç­‰å¾…æœåŠ¡å°±ç»ªï¼Œå‡å°‘æ€»ä½“éƒ¨ç½²æ—¶é—´

ğŸ¯ å·¥ä½œåŸç†ï¼š
- ä½¿ç”¨ asyncio.Semaphore æ§åˆ¶å•ä¸ªæ‰¹æ¬¡å†…çš„æœ€å¤§å¹¶å‘æ•°
- é€šè¿‡ asyncio.gather å®ç°åŒä¸€æ‰¹æ¬¡å†…æœåŠ¡çš„å¹¶å‘éƒ¨ç½²
- ä¾èµ– DependencyResolver çš„æ‹“æ‰‘æ’åºç»“æœè¿›è¡Œæ‰¹æ¬¡åŒ–éƒ¨ç½²
- æ”¯æŒè¶…æ—¶æ§åˆ¶å’Œå¼‚å¸¸å¤„ç†ï¼Œç¡®ä¿éƒ¨ç½²è¿‡ç¨‹çš„ç¨³å®šæ€§

ğŸ’¡ æ€§èƒ½ä¼˜åŠ¿ï¼š
- ç›¸æ¯”ä¸²è¡Œéƒ¨ç½²ï¼Œå¯èŠ‚çœ 30%-70% çš„æ€»éƒ¨ç½²æ—¶é—´
- æ‰¹æ¬¡å†…å¹¶å‘åº¦å¯é…ç½®ï¼Œé€‚åº”ä¸åŒç¡¬ä»¶ç¯å¢ƒ
- æ™ºèƒ½é‡è¯•åªå¤„ç†å¤±è´¥æœåŠ¡ï¼Œé¿å…é‡å¤éƒ¨ç½²æˆåŠŸçš„æœåŠ¡
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime
from enum import Enum
from dataclasses import dataclass

from .scenario_manager import ServiceDeployment
from .dependency_resolver import ServiceNode, DependencyStatus


class ConcurrentDeploymentError(Exception):
    """å¹¶å‘éƒ¨ç½²ä¸“ç”¨å¼‚å¸¸"""
    pass


class ServiceDeploymentTimeout(ConcurrentDeploymentError):
    """æœåŠ¡éƒ¨ç½²è¶…æ—¶å¼‚å¸¸"""
    pass


class DependencyError(ConcurrentDeploymentError):
    """ä¾èµ–æ£€æŸ¥å¼‚å¸¸"""
    pass


class NodeDeploymentError(ConcurrentDeploymentError):
    """èŠ‚ç‚¹éƒ¨ç½²å¼‚å¸¸"""
    pass


class DeploymentStatus(Enum):
    """éƒ¨ç½²çŠ¶æ€"""
    PENDING = "pending"
    DEPLOYING = "deploying"
    SUCCESS = "success"
    FAILED = "failed"
    RETRYING = "retrying"


@dataclass
class ServiceDeploymentResult:
    """æœåŠ¡éƒ¨ç½²ç»“æœ"""
    service_name: str
    status: DeploymentStatus = DeploymentStatus.PENDING
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    error_message: str = ""
    retry_count: int = 0
    nodes_deployed: Optional[List[str]] = None

    def __post_init__(self):
        if self.nodes_deployed is None:
            self.nodes_deployed = []

    @property
    def duration(self) -> float:
        """è·å–éƒ¨ç½²è€—æ—¶ï¼ˆç§’ï¼‰"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return 0.0

    @property
    def is_success(self) -> bool:
        return self.status == DeploymentStatus.SUCCESS

    @property
    def is_failed(self) -> bool:
        return self.status == DeploymentStatus.FAILED


class ConcurrentDeploymentLogger:
    """å¹¶å‘éƒ¨ç½²ä¸“ç”¨æ—¥å¿—å™¨"""

    def __init__(self, main_logger: logging.Logger):
        self.main_logger = main_logger
        self.service_progress: Dict[str, Dict[str, Any]] = {}

    def log_deployment_plan(self, batches: List[List[ServiceNode]]):
        """è®°å½•éƒ¨ç½²è®¡åˆ’"""
        self.main_logger.info("\n" + "=" * 50)
        self.main_logger.info("=== Concurrent Deployment Plan ===")
        self.main_logger.info(f"ğŸ¯ Total batches: {len(batches)}")

        for i, batch in enumerate(batches, 1):
            service_names = [node.service.name for node in batch]
            self.main_logger.info(f"ğŸ“¦ Batch {i}/{len(batches)}: {service_names}")

        self.main_logger.info("=" * 50)

    def log_batch_start(self, batch_num: int, services: List[ServiceNode], total_batches: int = None):
        """æ‰¹æ¬¡å¼€å§‹æ—¥å¿—"""
        service_names = [s.service.name for s in services]
        batch_label = f"Batch {batch_num}/{total_batches}" if total_batches else f"Batch {batch_num}"

        # è®¡ç®—æ€»ä½“è¿›åº¦
        progress_percent = 0
        if total_batches and total_batches > 0:
            progress_percent = ((batch_num - 1) / total_batches) * 100

        self.main_logger.info(f"\nğŸš€ === {batch_label} Deployment Start ===")
        self.main_logger.info(f"ğŸ“Š Overall progress: {progress_percent:.0f}% ({batch_num-1}/{total_batches} batches completed)" if total_batches else "")
        self.main_logger.info(f"ğŸ¯ Services: {', '.join(service_names)}")
        self.main_logger.info(f"âš¡ Concurrent deployment of {len(services)} services")

    def log_service_progress(self, service_name: str, status: str, details: str = ""):
        """è®°å½•æœåŠ¡è¿›åº¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        timestamp = datetime.now()
        self.service_progress[service_name] = {
            'status': status,
            'details': details,
            'timestamp': timestamp
        }

        # å®æ—¶æ—¥å¿—è¾“å‡º
        time_str = timestamp.strftime("%H:%M:%S")
        if details:
            self.main_logger.info(f"[{time_str}] {service_name}: {status} - {details}")
        else:
            self.main_logger.info(f"[{time_str}] {service_name}: {status}")

    def log_batch_summary(self, batch_num: int, results: Dict[str, ServiceDeploymentResult], total_batches: int = None):
        """æ‰¹æ¬¡å®Œæˆæ±‡æ€»æ—¥å¿—"""
        successful = [name for name, result in results.items() if result.is_success]
        failed = [name for name, result in results.items() if result.is_failed]

        batch_label = f"Batch {batch_num}/{total_batches}" if total_batches else f"Batch {batch_num}"
        progress_percent = (batch_num / total_batches) * 100 if total_batches else 0

        self.main_logger.info(f"\nâœ… === {batch_label} Deployment Summary ===")
        if total_batches:
            self.main_logger.info(f"ğŸ“ˆ Overall progress: {progress_percent:.0f}% ({batch_num}/{total_batches} batches completed)")

        if successful:
            self.main_logger.info(f"âœ… Successful: {len(successful)} services")
            for service_name in successful:
                result = results[service_name]
                duration = result.duration
                self.main_logger.info(f"  âœ“ {service_name} ({duration:.1f}s)")

        if failed:
            self.main_logger.error(f"âœ— Failed: {len(failed)} services")
            for service_name in failed:
                result = results[service_name]
                retry_info = f" (retried {result.retry_count} times)" if result.retry_count > 0 else ""
                self.main_logger.error(f"  - {service_name}{retry_info}: {result.error_message}")

        self.main_logger.info("-" * 50)


class ConcurrentRetryStrategy:
    """ğŸ”„ å¹¶å‘åœºæ™¯ä¸‹çš„æ™ºèƒ½é‡è¯•ç­–ç•¥

    ğŸ“Š æ ¸å¿ƒç‰¹æ€§ï¼š
    - é€‰æ‹©æ€§é‡è¯•ï¼šåªé‡è¯•å¤±è´¥çš„æœåŠ¡ï¼Œä¿æŒæˆåŠŸæœåŠ¡è¿è¡Œ
    - æŒ‡æ•°é€€é¿ï¼šé‡è¯•é—´éš”å¯é…ç½®ï¼Œé¿å…ç«‹å³é‡è¯•åŠ å‰§é—®é¢˜
    - æ‰¹æ¬¡ä¿æŒï¼šé‡è¯•æ—¶ç»´æŒåŸæœ‰çš„ä¾èµ–å…³ç³»å’Œæ‰¹æ¬¡ç»“æ„
    - ğŸ†• æ™ºèƒ½è¶…æ—¶ï¼šæ ¹æ®é”™è¯¯ç±»å‹åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´

    ğŸ¯ å·¥ä½œæœºåˆ¶ï¼š
    1. é¦–æ¬¡éƒ¨ç½²æ•´ä¸ªæ‰¹æ¬¡
    2. è¯†åˆ«å¤±è´¥çš„æœåŠ¡å’Œé”™è¯¯ç±»å‹
    3. æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é‡è¯•è¶…æ—¶
    4. åªå¯¹å¤±è´¥æœåŠ¡è¿›è¡Œé‡è¯•éƒ¨ç½²
    5. é‡å¤ç›´åˆ°è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æˆ–å…¨éƒ¨æˆåŠŸ

    ğŸ’¡ æ€§èƒ½ä¼˜åŠ¿ï¼š
    - é¿å…é‡å¤éƒ¨ç½²å·²æˆåŠŸçš„æœåŠ¡ï¼ŒèŠ‚çœ50%-80%é‡è¯•æ—¶é—´
    - æ™ºèƒ½è¶…æ—¶å‡å°‘ä¸å¿…è¦çš„ç­‰å¾…æ—¶é—´
    - ä¸å½±å“ä¾èµ–å…³ç³»ï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§
    """

    def __init__(self, max_retries: int = 2, retry_delay: int = 30, retry_only_failed: bool = True, smart_timeout_config: Optional[dict] = None):
        self.max_retries = max_retries           # æœ€å¤§é‡è¯•æ¬¡æ•°
        self.retry_delay = retry_delay           # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        self.retry_only_failed = retry_only_failed  # æ˜¯å¦åªé‡è¯•å¤±è´¥çš„æœåŠ¡
        self.smart_timeout_config = smart_timeout_config or {}  # æ™ºèƒ½è¶…æ—¶é…ç½®
        self.logger = logging.getLogger("playbook.concurrent_retry")

    async def deploy_batch_with_retry(self, batch: List[ServiceNode], scenario_path: Path,
                                    deployer_func, logger: ConcurrentDeploymentLogger, docker_manager=None) -> Dict[str, ServiceDeploymentResult]:
        """ğŸ”„ å¸¦æ™ºèƒ½é‡è¯•çš„æ‰¹æ¬¡éƒ¨ç½²

        Args:
            batch: å½“å‰æ‰¹æ¬¡çš„æœåŠ¡èŠ‚ç‚¹åˆ—è¡¨
            scenario_path: åœºæ™¯é…ç½®è·¯å¾„
            deployer_func: å®é™…çš„éƒ¨ç½²å‡½æ•°
            logger: å¹¶å‘éƒ¨ç½²æ—¥å¿—å™¨

        Returns:
            Dict[str, ServiceDeploymentResult]: æœåŠ¡ååˆ°éƒ¨ç½²ç»“æœçš„æ˜ å°„

        ğŸ¯ ç®—æ³•æµç¨‹ï¼š
        1. é¦–æ¬¡éƒ¨ç½²æ•´ä¸ªæ‰¹æ¬¡
        2. æ£€æŸ¥éƒ¨ç½²ç»“æœï¼Œè¯†åˆ«å¤±è´¥çš„æœåŠ¡
        3. å¦‚æœæœ‰å¤±è´¥ä¸”æœªè¾¾åˆ°é‡è¯•ä¸Šé™ï¼Œåªé‡è¯•å¤±è´¥çš„æœåŠ¡
        4. é‡å¤æ­¥éª¤2-3ç›´åˆ°å…¨éƒ¨æˆåŠŸæˆ–è¾¾åˆ°é‡è¯•ä¸Šé™
        5. è¿”å›æ‰€æœ‰æœåŠ¡çš„æœ€ç»ˆéƒ¨ç½²ç»“æœ

        ğŸ’¡ ä¼˜åŒ–è¦ç‚¹ï¼š
        - æˆåŠŸçš„æœåŠ¡ä¸ä¼šè¢«é‡å¤éƒ¨ç½²ï¼ŒèŠ‚çœæ—¶é—´å’Œèµ„æº
        - å¤±è´¥æœåŠ¡çš„é‡è¯•ä¸å½±å“æˆåŠŸæœåŠ¡çš„è¿è¡ŒçŠ¶æ€
        - é‡è¯•é—´éš”ç»™ç³»ç»Ÿæ¢å¤æ—¶é—´ï¼Œæé«˜é‡è¯•æˆåŠŸç‡
        """
        all_services = {node.service.name: node for node in batch}
        remaining_services = all_services.copy()
        final_results = {}

        for attempt in range(self.max_retries + 1):
            if not remaining_services:
                break

            if attempt > 0:
                self.logger.info(f"Retrying failed services (attempt {attempt + 1}): {list(remaining_services.keys())}")
                logger.log_service_progress("RETRY", f"Attempt {attempt + 1}", f"Retrying {len(remaining_services)} services")

                # ğŸ” é‡è¯•å‰æ£€æŸ¥æœåŠ¡çŠ¶æ€ - å¯èƒ½å·²è¢«æ‰‹åŠ¨æ¢å¤
                if docker_manager:
                    await self._check_services_before_retry(remaining_services, logger, final_results, docker_manager)

                # å¦‚æœæ‰€æœ‰æœåŠ¡éƒ½å·²æ¢å¤ï¼Œè·³è¿‡é‡è¯•
                if not remaining_services:
                    self.logger.info("All services have been recovered, skipping retry")
                    break

                await asyncio.sleep(self.retry_delay)

            # éƒ¨ç½²å½“å‰å‰©ä½™çš„æœåŠ¡
            batch_results = await deployer_func(list(remaining_services.values()), scenario_path, logger, attempt)

            # æ›´æ–°ç»“æœå¹¶ç§»é™¤æˆåŠŸçš„æœåŠ¡
            for service_name, result in batch_results.items():
                final_results[service_name] = result
                if result.is_success and service_name in remaining_services:
                    del remaining_services[service_name]
                    logger.log_service_progress(service_name, "SUCCESS", f"Deployed successfully after {attempt + 1} attempt(s)")

        # æ ‡è®°æœ€ç»ˆå¤±è´¥çš„æœåŠ¡
        for service_name in remaining_services:
            if service_name in final_results:
                final_results[service_name].status = DeploymentStatus.FAILED

        return final_results

    async def _check_services_before_retry(self, remaining_services: Dict[str, ServiceNode],
                                          logger: ConcurrentDeploymentLogger,
                                          final_results: Dict[str, ServiceDeploymentResult],
                                          docker_manager):
        """ğŸ” é‡è¯•å‰æ£€æŸ¥æœåŠ¡çŠ¶æ€ - æ£€æµ‹æ‰‹åŠ¨ä¿®å¤çš„æœåŠ¡

        Args:
            remaining_services: å¾…é‡è¯•çš„æœåŠ¡ï¼ˆä¼šå°±åœ°ä¿®æ”¹ï¼‰
            logger: æ—¥å¿—è®°å½•å™¨
            final_results: æœ€ç»ˆç»“æœå­—å…¸ï¼ˆä¼šæ›´æ–°æˆåŠŸçš„æœåŠ¡ï¼‰
        """
        if not remaining_services:
            return

        self.logger.info("Checking service status before retry...")
        recovered_services = []

        # å¹¶å‘æ£€æŸ¥æ‰€æœ‰å¾…é‡è¯•æœåŠ¡çš„çŠ¶æ€
        async def check_single_service_status(service_name: str, service_node: ServiceNode) -> tuple[str, bool]:
            try:
                # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡ŒåŒæ­¥çš„Dockerç®¡ç†å™¨æ–¹æ³•
                loop = asyncio.get_event_loop()

                # æ£€æŸ¥æœåŠ¡åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„çŠ¶æ€
                all_nodes_running = True
                for node_name in service_node.service.nodes:
                    status = await loop.run_in_executor(
                        None, self._get_service_status_sync, service_name, node_name, docker_manager
                    )
                    if not status.get('running', False):
                        all_nodes_running = False
                        break

                return service_name, all_nodes_running
            except Exception as e:
                self.logger.warning(f"Failed to check status for {service_name}: {e}")
                return service_name, False

        # å¹¶å‘æ£€æŸ¥æ‰€æœ‰æœåŠ¡
        check_tasks = [
            check_single_service_status(name, node)
            for name, node in remaining_services.items()
        ]

        status_results = await asyncio.gather(*check_tasks, return_exceptions=True)

        # å¤„ç†æ£€æŸ¥ç»“æœ
        for result in status_results:
            if isinstance(result, Exception):
                self.logger.warning(f"Service status check failed: {result}")
                continue

            if not isinstance(result, tuple) or len(result) != 2:
                self.logger.warning(f"Invalid status check result format: {result}")
                continue

            service_name, is_running = result
            if is_running:
                # æœåŠ¡å·²æ¢å¤ï¼Œæ ‡è®°ä¸ºæˆåŠŸ
                recovered_services.append(service_name)
                service_node = remaining_services[service_name]

                # åˆ›å»ºæˆåŠŸçš„éƒ¨ç½²ç»“æœ
                if service_name not in final_results:
                    final_results[service_name] = ServiceDeploymentResult(service_name=service_name)

                final_results[service_name].status = DeploymentStatus.SUCCESS
                service_node.status = DependencyStatus.RESOLVED

                logger.log_service_progress(
                    service_name, "RECOVERED",
                    "Service detected as running (manually recovered)"
                )

        # ä»å¾…é‡è¯•åˆ—è¡¨ä¸­ç§»é™¤å·²æ¢å¤çš„æœåŠ¡
        for service_name in recovered_services:
            del remaining_services[service_name]
            self.logger.info(f"Service {service_name} detected as recovered, removed from retry list")

        if recovered_services:
            self.logger.info(f"Detected {len(recovered_services)} recovered services: {recovered_services}")

    def _get_service_status_sync(self, service_name: str, node_name: str, docker_manager=None) -> Dict[str, Any]:
        """åŒæ­¥è·å–æœåŠ¡çŠ¶æ€çš„åŒ…è£…æ–¹æ³•"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨ä¼ å…¥çš„docker_manager
            if docker_manager and hasattr(docker_manager, 'get_service_status'):
                return docker_manager.get_service_status(service_name, node_name)

            # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•ä»selfè·å–
            local_docker_manager = getattr(self, 'docker_manager', None)
            if local_docker_manager and hasattr(local_docker_manager, 'get_service_status'):
                return local_docker_manager.get_service_status(service_name, node_name)

            # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›Falseï¼Œä½†ä¸è¾“å‡ºè­¦å‘Šï¼ˆå› ä¸ºè¿™åœ¨é‡è¯•æ—¶æ˜¯æ­£å¸¸çš„ï¼‰
            return {'running': False, 'error': 'Docker manager not available'}

        except Exception as e:
            self.logger.warning(f"Failed to get service status for {service_name} on {node_name}: {e}")
            return {'running': False, 'error': str(e)}

    def get_smart_timeout(self, error_message: str, default_timeout: int) -> int:
        """ğŸ§  æ ¹æ®é”™è¯¯ä¿¡æ¯æ™ºèƒ½è°ƒæ•´è¶…æ—¶æ—¶é—´

        Args:
            error_message: é”™è¯¯ä¿¡æ¯
            default_timeout: é»˜è®¤è¶…æ—¶æ—¶é—´

        Returns:
            int: è°ƒæ•´åçš„è¶…æ—¶æ—¶é—´
        """
        if not self.smart_timeout_config.get('enabled', False):
            return default_timeout

        error_patterns = self.smart_timeout_config.get('error_patterns', {})
        timeout_mapping = self.smart_timeout_config.get('timeout_by_error_type', {})

        error_lower = error_message.lower()

        # æ£€æŸ¥é”™è¯¯ç±»å‹åŒ¹é…
        for error_type, patterns in error_patterns.items():
            for pattern in patterns:
                import re
                if re.search(pattern.lower(), error_lower):
                    smart_timeout = timeout_mapping.get(error_type, default_timeout)
                    self.logger.info(f"Smart timeout: detected {error_type}, adjusting timeout from {default_timeout}s to {smart_timeout}s")
                    return smart_timeout

        # æœªåŒ¹é…ä»»ä½•æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤å€¼
        return timeout_mapping.get('default', default_timeout)


class ConcurrentServiceDeployer:
    """ğŸš€ å¹¶å‘æœåŠ¡éƒ¨ç½²å™¨ - æ ¸å¿ƒéƒ¨ç½²å¼•æ“

    ğŸ“Š èŒè´£èŒƒå›´ï¼š
    1. åè°ƒæ‰¹æ¬¡é—´çš„ä¸²è¡Œæ‰§è¡Œå’Œæ‰¹æ¬¡å†…çš„å¹¶å‘æ‰§è¡Œ
    2. ç®¡ç†æœåŠ¡éƒ¨ç½²çš„ç”Ÿå‘½å‘¨æœŸï¼ˆä¾èµ–æ£€æŸ¥ â†’ éƒ¨ç½² â†’ å¥åº·æ£€æŸ¥ï¼‰
    3. å¤„ç†å¼‚æ­¥ä»»åŠ¡è°ƒåº¦å’Œé”™è¯¯æ¢å¤
    4. æä¾›ç»Ÿä¸€çš„éƒ¨ç½²ç»“æœç®¡ç†å’ŒçŠ¶æ€åŒæ­¥

    ğŸ¯ æ ¸å¿ƒæœºåˆ¶ï¼š
    - ä½¿ç”¨ asyncio.Semaphore å®ç°å¹¶å‘æ§åˆ¶
    - é€šè¿‡ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰¹æ¬¡å†…çš„æœåŠ¡éƒ¨ç½²
    - é›†æˆä¾èµ–æ£€æŸ¥ã€èŠ‚ç‚¹éƒ¨ç½²ã€å¥åº·æ£€æŸ¥çš„å®Œæ•´æµç¨‹
    - æ”¯æŒè¶…æ—¶æ§åˆ¶å’Œå¼‚å¸¸åˆ†ç±»å¤„ç†

    ğŸ’¡ æ¶æ„ä¼˜åŠ¿ï¼š
    - æ‰¹æ¬¡çº§åˆ«çš„æ•…éšœéš”ç¦»ï¼Œå•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¸å½±å“åç»­æ‰¹æ¬¡
    - æœåŠ¡çº§åˆ«çš„ç‹¬ç«‹éƒ¨ç½²ï¼Œå•ä¸ªæœåŠ¡å¤±è´¥ä¸å½±å“åŒæ‰¹æ¬¡å…¶ä»–æœåŠ¡
    - å¼‚æ­¥æ‰§è¡Œå‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæé«˜æ•´ä½“éƒ¨ç½²æ•ˆç‡
    """

    def __init__(self, docker_manager, dependency_resolver):
        self.docker_manager = docker_manager        # DockeræœåŠ¡ç®¡ç†å™¨
        self.dependency_resolver = dependency_resolver  # ä¾èµ–å…³ç³»è§£æå™¨
        self.logger = logging.getLogger("playbook.concurrent_deployer")

    def _set_deployment_result_status(self, result: ServiceDeploymentResult, service_node: ServiceNode,
                                     success: bool, error_message: str = ""):
        """ç»Ÿä¸€è®¾ç½®éƒ¨ç½²ç»“æœå’ŒæœåŠ¡èŠ‚ç‚¹çŠ¶æ€"""
        if success:
            result.status = DeploymentStatus.SUCCESS
            service_node.status = DependencyStatus.RESOLVED
        else:
            result.status = DeploymentStatus.FAILED
            service_node.status = DependencyStatus.FAILED
            if error_message:
                result.error_message = error_message


    async def deploy_services_concurrent(self, batches: List[List[ServiceNode]], scenario_path: Path,
                                       logger: ConcurrentDeploymentLogger,
                                       max_concurrent: int = 5,
                                       retry_strategy: Optional[ConcurrentRetryStrategy] = None,
                                       deployment_timeout: int = 600) -> Dict[str, ServiceDeploymentResult]:
        """ğŸš€ å¹¶å‘éƒ¨ç½²æ‰€æœ‰æ‰¹æ¬¡çš„æœåŠ¡ - æ ¸å¿ƒéƒ¨ç½²åè°ƒå™¨

        Args:
            batches: æŒ‰ä¾èµ–å…³ç³»æ’åºçš„æœåŠ¡æ‰¹æ¬¡åˆ—è¡¨
            scenario_path: åœºæ™¯é…ç½®è·¯å¾„
            logger: å¹¶å‘éƒ¨ç½²æ—¥å¿—å™¨
            max_concurrent: æ‰¹æ¬¡å†…æœ€å¤§å¹¶å‘æœåŠ¡æ•°
            retry_strategy: é‡è¯•ç­–ç•¥ï¼ˆå¯é€‰ï¼‰
            deployment_timeout: éƒ¨ç½²è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            Dict[str, ServiceDeploymentResult]: æ‰€æœ‰æœåŠ¡çš„éƒ¨ç½²ç»“æœ

        ğŸ¯ æ‰§è¡Œæµç¨‹ï¼š
        1. è®°å½•å®Œæ•´çš„éƒ¨ç½²è®¡åˆ’ï¼ˆæ‰¹æ¬¡åˆ†å¸ƒã€æœåŠ¡ä¾èµ–ï¼‰
        2. æŒ‰æ‰¹æ¬¡é¡ºåºä¸²è¡Œæ‰§è¡Œï¼ˆç¡®ä¿ä¾èµ–å…³ç³»ï¼‰
        3. æ‰¹æ¬¡å†…ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°ï¼ˆé˜²æ­¢èµ„æºäº‰æŠ¢ï¼‰
        4. é›†æˆæ™ºèƒ½é‡è¯•æœºåˆ¶ï¼ˆæé«˜éƒ¨ç½²æˆåŠŸç‡ï¼‰
        5. æä¾›è¯¦ç»†çš„æ‰§è¡ŒçŠ¶æ€å’Œç»“æœç»Ÿè®¡

        âš ï¸  æ•…éšœå¤„ç†ï¼š
        - å•ä¸ªæ‰¹æ¬¡å¤±è´¥ä¼šç»ˆæ­¢åç»­æ‰¹æ¬¡çš„æ‰§è¡Œ
        - å¤±è´¥çš„æœåŠ¡ä¼šæ ‡è®°å‰©ä½™æ‰¹æ¬¡ä¸ºè·³è¿‡çŠ¶æ€
        - é€šè¿‡å¼‚å¸¸ä¼ æ’­æœºåˆ¶é€šçŸ¥ä¸Šå±‚è°ƒç”¨è€…

        ğŸ’¡ æ€§èƒ½ç‰¹ç‚¹ï¼š
        - æ‰¹æ¬¡é—´ä¸²è¡Œç¡®ä¿ä¾èµ–å…³ç³»æ­£ç¡®
        - æ‰¹æ¬¡å†…å¹¶å‘å‡å°‘æ€»ä½“éƒ¨ç½²æ—¶é—´
        - å¯é…ç½®çš„å¹¶å‘åº¦é€‚åº”ä¸åŒç¡¬ä»¶ç¯å¢ƒ
        """

        if retry_strategy is None:
            retry_strategy = ConcurrentRetryStrategy()

        # è®°å½•éƒ¨ç½²è®¡åˆ’
        logger.log_deployment_plan(batches)

        all_results = {}

        # æ‰¹æ¬¡é—´ä¸²è¡Œï¼Œæ‰¹æ¬¡å†…å¹¶å‘
        for i, batch in enumerate(batches, 1):
            logger.log_batch_start(i, batch, len(batches))

            # å¸¦é‡è¯•çš„æ‰¹æ¬¡éƒ¨ç½²
            batch_results = await retry_strategy.deploy_batch_with_retry(
                batch, scenario_path,
                lambda services, path, log, attempt: self._deploy_batch_concurrent(
                    services, path, log, max_concurrent, attempt, deployment_timeout
                ),
                logger,
                self.docker_manager
            )

            # è®°å½•æ‰¹æ¬¡ç»“æœ
            logger.log_batch_summary(i, batch_results, len(batches))
            all_results.update(batch_results)

            # æ£€æŸ¥æ‰¹æ¬¡å¤±è´¥
            failed_services = [name for name, result in batch_results.items() if result.is_failed]
            if failed_services:
                self.logger.error(f"Batch {i} deployment failed for services: {failed_services}")
                # æ ‡è®°å‰©ä½™æ‰¹æ¬¡çš„æœåŠ¡ä¸ºè·³è¿‡
                for remaining_batch in batches[i:]:
                    for service_node in remaining_batch:
                        result = ServiceDeploymentResult(
                            service_name=service_node.service.name,
                            status=DeploymentStatus.FAILED,
                            error_message="Previous batch failed"
                        )
                        all_results[service_node.service.name] = result

                raise RuntimeError(f"Service deployment failed: {failed_services}")

        return all_results

    async def _deploy_batch_concurrent(self, batch: List[ServiceNode], scenario_path: Path,
                                     logger: ConcurrentDeploymentLogger, max_concurrent: int,
                                     attempt: int = 0, timeout: int = 600) -> Dict[str, ServiceDeploymentResult]:
        """ğŸ“¦ æ‰¹æ¬¡å†…å¹¶å‘éƒ¨ç½² - ä¿¡å·é‡æ§åˆ¶çš„å¹¶å‘æ‰§è¡Œå™¨

        ğŸ¯ æ ¸å¿ƒæœºåˆ¶ï¼š
        - ä½¿ç”¨ asyncio.Semaphore(max_concurrent) æ§åˆ¶å¹¶å‘åº¦
        - é€šè¿‡ asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰æœåŠ¡éƒ¨ç½²ä»»åŠ¡
        - æ¯ä¸ªæœåŠ¡ä½œä¸ºç‹¬ç«‹çš„å¼‚æ­¥ä»»åŠ¡ï¼Œäº’ä¸é˜»å¡

        ğŸ’¡ å¹¶å‘æ¨¡å‹ï¼š
        1. åˆ›å»ºä¿¡å·é‡é™åˆ¶æœ€å¤§å¹¶å‘æ•°
        2. ä¸ºæ‰¹æ¬¡ä¸­æ¯ä¸ªæœåŠ¡åˆ›å»ºå¼‚æ­¥éƒ¨ç½²ä»»åŠ¡
        3. ä½¿ç”¨ gather ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        4. ç»Ÿä¸€å¤„ç†ç»“æœå’Œå¼‚å¸¸

        ğŸš¦ å¹¶å‘æ§åˆ¶ï¼š
        - ä¿¡å·é‡ç¡®ä¿ä¸è¶…è¿‡ max_concurrent ä¸ªæœåŠ¡åŒæ—¶éƒ¨ç½²
        - é¿å…ç³»ç»Ÿèµ„æºäº‰æŠ¢å’Œç½‘ç»œè¿æ¥è¿‡è½½
        - æ”¯æŒåŠ¨æ€è°ƒæ•´å¹¶å‘åº¦ä»¥é€‚åº”ä¸åŒç¯å¢ƒ
        """
        semaphore = asyncio.Semaphore(max_concurrent)

        async def deploy_single_service(service_node: ServiceNode) -> Tuple[str, ServiceDeploymentResult]:
            """å•ä¸ªæœåŠ¡çš„å¼‚æ­¥éƒ¨ç½²åŒ…è£…å™¨ - è‡ªåŠ¨è·å–å’Œé‡Šæ”¾ä¿¡å·é‡"""
            async with semaphore:  # è‡ªåŠ¨ä¿¡å·é‡ç®¡ç†ï¼šè·å–è®¸å¯ â†’ æ‰§è¡Œéƒ¨ç½² â†’ é‡Šæ”¾è®¸å¯
                return await self._deploy_service_async(service_node, scenario_path, logger, attempt, timeout)

        # å¹¶å‘æ‰§è¡Œæ‰¹æ¬¡å†…æ‰€æœ‰æœåŠ¡
        tasks = [deploy_single_service(node) for node in batch]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœ
        batch_results = {}
        for result in results:
            if isinstance(result, Exception):
                self.logger.error(f"Service deployment task failed: {result}")
                continue

            if not isinstance(result, tuple) or len(result) != 2:
                self.logger.warning(f"Invalid deployment result format: {result}")
                continue

            service_name, deploy_result = result
            batch_results[service_name] = deploy_result

        return batch_results

    async def _deploy_service_async(self, service_node: ServiceNode, scenario_path: Path,
                                  logger: ConcurrentDeploymentLogger, attempt: int = 0,
                                  deployment_timeout: int = 600) -> Tuple[str, ServiceDeploymentResult]:
        """å¼‚æ­¥éƒ¨ç½²å•ä¸ªæœåŠ¡"""
        service = service_node.service
        result = ServiceDeploymentResult(service_name=service.name)
        result.start_time = datetime.now()
        result.retry_count = attempt
        result.status = DeploymentStatus.DEPLOYING

        try:
            # ç­‰å¾…ä¾èµ–æœåŠ¡å°±ç»ª
            logger.log_service_progress(service.name, "CHECKING_DEPS", "Checking dependencies")

            if not await self._wait_for_dependencies_async(service, deployment_timeout):
                self._set_deployment_result_status(result, service_node, False, "Dependencies not ready")
                result.end_time = datetime.now()
                return service.name, result

            # åœ¨æ‰€æœ‰æŒ‡å®šèŠ‚ç‚¹ä¸Šéƒ¨ç½²æœåŠ¡
            logger.log_service_progress(service.name, "DEPLOYING", f"Deploying on {len(service.nodes)} nodes")

            # åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¯• (attempt > 0 è¡¨ç¤ºé‡è¯•)
            is_retry = attempt > 0
            success = await self._deploy_on_all_nodes_async(service, scenario_path, result, logger, deployment_timeout, is_retry)

            if success:
                # ç­‰å¾…æœåŠ¡å°±ç»ª
                logger.log_service_progress(service.name, "WAITING", "Waiting for service to be ready")
                if await self._wait_for_service_ready_async(service, deployment_timeout):
                    self._set_deployment_result_status(result, service_node, True)
                else:
                    self._set_deployment_result_status(result, service_node, False, "Service did not become ready")
            else:
                self._set_deployment_result_status(result, service_node, False)

        except asyncio.TimeoutError:
            error_msg = f"Deployment timeout after {deployment_timeout}s"
            self._set_deployment_result_status(result, service_node, False, error_msg)
            self.logger.error(f"Service {service.name} deployment timeout: {error_msg}")
        except DependencyError as e:
            error_msg = f"Dependency error: {str(e)}"
            self._set_deployment_result_status(result, service_node, False, error_msg)
            self.logger.error(f"Service {service.name} dependency failed: {error_msg}")
        except NodeDeploymentError as e:
            error_msg = f"Node deployment error: {str(e)}"
            self._set_deployment_result_status(result, service_node, False, error_msg)
            self.logger.error(f"Service {service.name} node deployment failed: {error_msg}")
        except Exception as e:
            error_msg = f"Unexpected error: {str(e)}"
            self._set_deployment_result_status(result, service_node, False, error_msg)
            self.logger.error(f"Service {service.name} deployment failed: {error_msg}")
            import traceback
            self.logger.debug(f"Full traceback: {traceback.format_exc()}")

        result.end_time = datetime.now()
        return service.name, result

    async def _wait_for_dependencies_async(self, service: ServiceDeployment,
                                          deployment_timeout: int = 600) -> bool:
        """å¼‚æ­¥ç­‰å¾…ä¾èµ–æœåŠ¡å°±ç»ª"""
        if not service.depends_on:
            return True

        try:
            # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•ï¼Œæ·»åŠ è¶…æ—¶ä¿æŠ¤
            loop = asyncio.get_event_loop()
            return await asyncio.wait_for(
                loop.run_in_executor(
                    None, self.dependency_resolver.wait_for_dependencies, service, deployment_timeout
                ),
                timeout=deployment_timeout
            )
        except asyncio.TimeoutError:
            raise DependencyError(f"Dependency check timeout after {deployment_timeout}s for service {service.name}")
        except Exception as e:
            raise DependencyError(f"Dependency check failed for service {service.name}: {str(e)}")

    async def _deploy_on_all_nodes_async(self, service: ServiceDeployment, scenario_path: Path,
                                       result: ServiceDeploymentResult, logger: ConcurrentDeploymentLogger,
                                       deployment_timeout: int = 600, is_retry: bool = False) -> bool:
        """åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¼‚æ­¥éƒ¨ç½²æœåŠ¡"""

        async def deploy_on_node(node_name: str) -> Tuple[str, bool]:
            try:
                loop = asyncio.get_event_loop()
                success = await asyncio.wait_for(
                    loop.run_in_executor(
                        None, self.docker_manager.deploy_service, scenario_path, service, node_name, deployment_timeout, is_retry
                    ),
                    timeout=deployment_timeout
                )
                if success:
                    if result.nodes_deployed is None:
                        result.nodes_deployed = []
                    result.nodes_deployed.append(node_name)
                return node_name, success
            except asyncio.TimeoutError:
                raise NodeDeploymentError(f"Deployment timeout on node {node_name} after {deployment_timeout}s")
            except Exception as e:
                raise NodeDeploymentError(f"Deployment failed on node {node_name}: {str(e)}")

        # åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¹¶å‘éƒ¨ç½²
        tasks = [deploy_on_node(node_name) for node_name in service.nodes]
        node_results = await asyncio.gather(*tasks, return_exceptions=True)

        success_count = 0
        for node_result in node_results:
            if isinstance(node_result, Exception):
                logger.log_service_progress(service.name, "ERROR", f"Node deployment error: {node_result}")
                continue

            if not isinstance(node_result, tuple) or len(node_result) != 2:
                logger.log_service_progress(service.name, "ERROR", f"Invalid node deployment result format: {node_result}")
                continue

            node_name, success = node_result
            if success:
                success_count += 1
            else:
                logger.log_service_progress(service.name, "FAILED", f"Failed on node {node_name}")

        # æ‰€æœ‰èŠ‚ç‚¹éƒ½æˆåŠŸæ‰ç®—æˆåŠŸ
        return success_count == len(service.nodes)

    async def _wait_for_service_ready_async(self, service: ServiceDeployment,
                                           deployment_timeout: int = 600) -> bool:
        """å¼‚æ­¥ç­‰å¾…æœåŠ¡å°±ç»ª"""
        try:
            loop = asyncio.get_event_loop()
            return await asyncio.wait_for(
                loop.run_in_executor(
                    None, self.dependency_resolver.wait_for_service_ready, service.name, service.nodes, deployment_timeout
                ),
                timeout=deployment_timeout
            )
        except asyncio.TimeoutError:
            raise ServiceDeploymentTimeout(f"Service {service.name} readiness check timeout after {deployment_timeout}s")
        except Exception as e:
            self.logger.warning(f"Service readiness check failed for {service.name}: {str(e)}")
            return False