"""
ç»“æœæŠ¥å‘Šç”Ÿæˆå™¨
è´Ÿè´£ç”Ÿæˆå„ç§æ ¼å¼çš„æµ‹è¯•ç»“æœæŠ¥å‘Š
"""

import json
import yaml
import tarfile
import logging
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
from datetime import datetime

from .result_models import CollectionSummary, ResultSummary, TestSuiteResultSummary


class ResultReporter:
    """ç»“æœæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger("playbook.result_reporter")
    
    def save_result_summary(self, result_dir: Path, summary: ResultSummary):
        """ä¿å­˜ç»“æœæ‘˜è¦"""
        summary_file = result_dir / "result_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary.to_dict(), f, indent=2, ensure_ascii=False)
        
        # åŒæ—¶ä¿å­˜YAMLæ ¼å¼
        yaml_file = result_dir / "result_summary.yaml"
        with open(yaml_file, 'w', encoding='utf-8') as f:
            yaml.dump(summary.to_dict(), f, default_flow_style=False, allow_unicode=True)
        
        self.logger.debug(f"Saved result summary to {summary_file}")
    
    def generate_reports_v2(self, result_dir: Path, summary: ResultSummary,
                           collection_summary: CollectionSummary):
        """ç”ŸæˆæŠ¥å‘Š - æ–°ç‰ˆæœ¬"""
        try:
            # ç”ŸæˆMarkdownæŠ¥å‘Š
            self.generate_markdown_report_v2(result_dir, summary, collection_summary)
            
            # ç”Ÿæˆæ”¶é›†ç»Ÿè®¡æŠ¥å‘Š
            self.generate_collection_report(result_dir, collection_summary)
            
            # ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
            self.generate_performance_report(result_dir, summary)

        except Exception as e:
            self.logger.warning(f"Failed to generate some reports: {e}")

    def generate_markdown_report_v2(self, result_dir: Path, summary: ResultSummary,
                                    collection_summary: CollectionSummary):
        """ç”ŸæˆMarkdownæŠ¥å‘Š - æ–°ç‰ˆæœ¬"""
        try:
            def safe_format(value, format_spec=''):
                if value is None:
                    return 'N/A'
                if format_spec:
                    return f"{value:{format_spec}}"
                return str(value)

            report_content = f"""# æµ‹è¯•ç»“æœæŠ¥å‘Š - {summary.scenario_name}

## åŸºæœ¬ä¿¡æ¯
- **åœºæ™¯åç§°**: {summary.scenario_name}
- **æµ‹è¯•æ—¶é—´**: {summary.timestamp}
- **æ”¶é›†æ¨¡å¼**: {collection_summary.mode}
- **æ€»èŠ‚ç‚¹æ•°**: {summary.total_nodes}
- **æˆåŠŸèŠ‚ç‚¹æ•°**: {summary.successful_nodes}
- **å¤±è´¥èŠ‚ç‚¹æ•°**: {summary.failed_nodes}

## æµ‹è¯•ç»“æœæ”¶é›†
- **æµ‹è¯•artifacts**: {collection_summary.test_artifacts.get('count', 0)} ä¸ªæ–‡ä»¶
- **artifactså¤§å°**: {safe_format(collection_summary.test_artifacts.get('total_size_mb', 0), '.2f')} MB
- **æ€»æ–‡ä»¶æ•°**: {collection_summary.total_files_collected}
- **æ€»å¤§å°**: {safe_format(collection_summary.total_size_mb, '.2f')} MB

## åˆ†å¸ƒå¼ç»“æœæ”¶é›†

"""

            # æ¯ä¸ªèŠ‚ç‚¹çš„æ”¶é›†ç»“æœ
            if collection_summary.node_results:
                report_content += "### èŠ‚ç‚¹æ”¶é›†ç»“æœ\\n\\n"
                report_content += "| èŠ‚ç‚¹åç§° | æœåŠ¡æ—¥å¿— | ç³»ç»Ÿæ—¥å¿— | é”™è¯¯æ•° |\\n"
                report_content += "|----------|----------|----------|----------|\\n"

                for node_name, node_info in collection_summary.node_results.items():
                    services = ', '.join(node_info.get('services_collected', []))
                    system_logs = 'âœ“' if node_info.get('system_logs_collected', False) else 'âœ—'
                    error_count = len(node_info.get('collection_errors', []))
                    report_content += f"| {node_name} | {services} | {system_logs} | {error_count} |\\n"

            # æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
            if summary.total_requests > 0:
                report_content += f"""
## æ€§èƒ½æŒ‡æ ‡
- **å¹³å‡ååé‡**: {safe_format(summary.avg_throughput, '.2f')} tokens/s
- **æœ€å¤§ååé‡**: {safe_format(summary.max_throughput, '.2f')} tokens/s
- **æœ€å°ååé‡**: {safe_format(summary.min_throughput, '.2f')} tokens/s
- **å¹³å‡å»¶è¿Ÿ**: {safe_format(summary.avg_latency, '.3f')} s
- **æ€»è¯·æ±‚æ•°**: {summary.total_requests}
- **æˆåŠŸè¯·æ±‚æ•°**: {summary.total_successful_requests}
- **æ€»ä½“æˆåŠŸç‡**: {safe_format(summary.overall_success_rate, '.2f')}%
"""

            # é”™è¯¯ä¿¡æ¯
            if collection_summary.collection_errors:
                report_content += "\\n## æ”¶é›†é”™è¯¯\\n\\n"
                for error in collection_summary.collection_errors:
                    report_content += f"- {error}\\n"

            markdown_file = result_dir / "scenario_test_report.md"
            with open(markdown_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            self.logger.debug(f"Generated Markdown report: {markdown_file}")

        except Exception as e:
            self.logger.error(f"Failed to generate Markdown report: {e}")

    def generate_collection_report(self, result_dir: Path, collection_summary: CollectionSummary):
        """ç”Ÿæˆæ”¶é›†ç»Ÿè®¡æŠ¥å‘Š"""
        try:
            report_content = f"""æ”¶é›†æ—¶é—´: {collection_summary.collection_time}
æ”¶é›†æ¨¡å¼: {collection_summary.mode}
æ€»æ–‡ä»¶æ•°: {collection_summary.total_files_collected}
æ€»å¤§å°: {collection_summary.total_size_mb:.2f} MB
é”™è¯¯æ•°: {len(collection_summary.collection_errors)}

æµ‹è¯•artifacts:
- æ•°é‡: {collection_summary.test_artifacts.get('count', 0)}
- å¤§å°: {collection_summary.test_artifacts.get('total_size_mb', 0):.2f} MB
- æ¥æº: {collection_summary.test_artifacts.get('source', 'unknown')}

èŠ‚ç‚¹ç»“æœ:
"""

            for node_name, node_info in collection_summary.node_results.items():
                report_content += f"\\n{node_name}:"
                report_content += f"\\n  æœåŠ¡æ—¥å¿—: {', '.join(node_info.get('services_collected', []))}"
                report_content += f"\\n  ç³»ç»Ÿæ—¥å¿—: {'Yes' if node_info.get('system_logs_collected', False) else 'No'}"
                if node_info.get('collection_errors'):
                    report_content += f"\\n  é”™è¯¯: {'; '.join(node_info['collection_errors'])}"

            if collection_summary.collection_errors:
                report_content += "\\n\\nå…¨å±€é”™è¯¯:\\n"
                for error in collection_summary.collection_errors:
                    report_content += f"- {error}\\n"

            collection_report_file = result_dir / "collection_report.txt"
            with open(collection_report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            self.logger.debug(f"Generated collection report: {collection_report_file}")

        except Exception as e:
            self.logger.error(f"Failed to generate collection report: {e}")
    
    def generate_performance_report(self, result_dir: Path, summary: ResultSummary):
        """ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        try:
            if summary.total_requests == 0:
                self.logger.debug("No performance data available, skipping performance report")
                return
            
            performance_data = {
                'summary': {
                    'scenario_name': summary.scenario_name,
                    'timestamp': summary.timestamp,
                    'total_nodes': summary.total_nodes,
                    'successful_nodes': summary.successful_nodes,
                    'failed_nodes': summary.failed_nodes
                },
                'metrics': {
                    'avg_throughput': summary.avg_throughput,
                    'max_throughput': summary.max_throughput,
                    'min_throughput': summary.min_throughput,
                    'avg_latency': summary.avg_latency,
                    'total_requests': summary.total_requests,
                    'total_successful_requests': summary.total_successful_requests,
                    'overall_success_rate': summary.overall_success_rate
                },
                'node_details': summary.node_results
            }
            
            # ä¿å­˜JSONæ ¼å¼çš„æ€§èƒ½æ•°æ®
            performance_file = result_dir / "performance_report.json"
            with open(performance_file, 'w', encoding='utf-8') as f:
                json.dump(performance_data, f, indent=2, ensure_ascii=False)
            
            self.logger.debug(f"Generated performance report: {performance_file}")
            
        except Exception as e:
            self.logger.error(f"Failed to generate performance report: {e}")

    def generate_suite_report(self, result_dir: Path, summary: Union[ResultSummary, TestSuiteResultSummary]):
        """ç”Ÿæˆæµ‹è¯•å¥—ä»¶æŠ¥å‘Š - ç”¨äºæ±‡æ€»æŠ¥å‘Š"""
        try:
            def safe_format(value, format_spec=''):
                if value is None:
                    return 'N/A'
                if format_spec:
                    return f"{value:{format_spec}}"
                return str(value)

            # æ£€æŸ¥summaryç±»å‹å¹¶ç”Ÿæˆç›¸åº”çš„æŠ¥å‘Š
            if isinstance(summary, TestSuiteResultSummary):
                # ç”Ÿæˆæµ‹è¯•å¥—ä»¶æ±‡æ€»æŠ¥å‘Š
                report_content = f"""# æµ‹è¯•å¥—ä»¶æ±‡æ€»æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **å¥—ä»¶åç§°**: {summary.suite_name}
- **æµ‹è¯•æ—¶é—´**: {summary.timestamp}
- **æ€»åœºæ™¯æ•°**: {summary.total_scenarios}
- **æˆåŠŸåœºæ™¯æ•°**: {summary.successful_scenarios}
- **å¤±è´¥åœºæ™¯æ•°**: {summary.failed_scenarios}
- **æ€»ä½“æˆåŠŸç‡**: {safe_format(summary.overall_success_rate_pct, '.1f')}%
- **æ€»æ‰§è¡Œæ—¶é—´**: {safe_format(summary.total_execution_time, '.1f')} ç§’

## æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
- **æ€»ä½“å¹³å‡ååé‡**: {safe_format(summary.overall_avg_throughput, '.2f')} tokens/s
- **æ€»ä½“æœ€å¤§ååé‡**: {safe_format(summary.overall_max_throughput, '.2f')} tokens/s
- **æ€»ä½“æˆåŠŸç‡**: {safe_format(summary.overall_success_rate, '.1f')}%

## æ–‡ä»¶ç»Ÿè®¡æ±‡æ€»
- **æ€»ç»“æœæ–‡ä»¶æ•°**: {summary.total_result_files}
- **æ€»æ–‡ä»¶å¤§å°**: {safe_format(summary.total_size_mb, '.2f')} MB

## å„åœºæ™¯è¯¦ç»†ç»“æœ

| åœºæ™¯åç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é•¿(ç§’) | ç»“æœæ–‡ä»¶æ•° | æ–‡ä»¶å¤§å°(MB) | æˆåŠŸèŠ‚ç‚¹ | å¤±è´¥èŠ‚ç‚¹ | é”™è¯¯ä¿¡æ¯ |
|---------|------|-------------|------------|-------------|----------|----------|----------|
"""

                for scenario_name, scenario_info in summary.scenario_summaries.items():
                    status_icon = "âœ…" if scenario_info.get('status') == 'completed' else "âŒ"
                    status = scenario_info.get('status', 'unknown')
                    duration = safe_format(scenario_info.get('duration_seconds', 0), '.1f')
                    result_files = scenario_info.get('result_files', 0)
                    result_size = safe_format(scenario_info.get('result_size_mb', 0), '.2f')
                    successful_nodes = scenario_info.get('successful_nodes', 0)
                    failed_nodes = scenario_info.get('failed_nodes', 0)
                    error_msg = scenario_info.get('error_message', '')[:50]  # æˆªæ–­é”™è¯¯ä¿¡æ¯
                    if len(scenario_info.get('error_message', '')) > 50:
                        error_msg += '...'

                    report_content += f"| {scenario_name} | {status_icon} {status} | {duration} | {result_files} | {result_size} | {successful_nodes} | {failed_nodes} | {error_msg} |\n"

                # æ·»åŠ å¥åº·æ£€æŸ¥å’Œæ‰§è¡Œæ‘˜è¦ä¿¡æ¯
                if summary.health_report:
                    report_content += "\n## å¥åº·æ£€æŸ¥æŠ¥å‘Š\n\n"
                    for key, value in summary.health_report.items():
                        report_content += f"- **{key}**: {value}\n"

                if summary.execution_summary:
                    report_content += "\n## æ‰§è¡Œæ‘˜è¦\n\n"
                    for key, value in summary.execution_summary.items():
                        report_content += f"- **{key}**: {value}\n"

            else:
                # åŸæœ‰çš„å•åœºæ™¯æŠ¥å‘Šé€»è¾‘ (ResultSummary)
                report_content = f"""# æµ‹è¯•ç»“æœæŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **åœºæ™¯åç§°**: {summary.scenario_name}
- **æµ‹è¯•æ—¶é—´**: {summary.timestamp}
- **æ€»èŠ‚ç‚¹æ•°**: {summary.total_nodes}
- **æˆåŠŸèŠ‚ç‚¹æ•°**: {summary.successful_nodes}
- **å¤±è´¥èŠ‚ç‚¹æ•°**: {summary.failed_nodes}

## æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
- **å¹³å‡ååé‡**: {safe_format(summary.avg_throughput, '.2f')} tokens/s
- **æœ€å¤§ååé‡**: {safe_format(summary.max_throughput, '.2f')} tokens/s
- **æœ€å°ååé‡**: {safe_format(summary.min_throughput, '.2f')} tokens/s
- **å¹³å‡å»¶è¿Ÿ**: {safe_format(summary.avg_latency, '.3f')} s
- **æ€»è¯·æ±‚æ•°**: {summary.total_requests}
- **æˆåŠŸè¯·æ±‚æ•°**: {summary.total_successful_requests}
- **æ€»ä½“æˆåŠŸç‡**: {safe_format(summary.overall_success_rate, '.1f')}%

## æ–‡ä»¶ç»Ÿè®¡
- **ç»“æœæ–‡ä»¶æ•°**: {summary.total_result_files}
- **æ€»æ–‡ä»¶å¤§å°**: {safe_format(summary.total_size_mb, '.2f')} MB

## å„èŠ‚ç‚¹è¯¦ç»†ç»“æœ

| èŠ‚ç‚¹åç§° | çŠ¶æ€ | ååé‡ | å¹³å‡å»¶è¿Ÿ | æˆåŠŸç‡ | æ‰§è¡Œæ—¶é•¿ |
|---------|------|--------|----------|--------|----------|
"""

                for node_name, result in summary.node_results.items():
                    status_icon = "âœ…" if result['status'] == 'completed' else "âŒ"
                    throughput = safe_format(result.get('throughput', 0), '.2f')
                    latency_mean = safe_format(result.get('latency_mean', 0), '.3f')
                    success_rate = safe_format(result.get('success_rate', 0), '.1f')
                    duration = safe_format(result.get('duration', 0), '.1f')
                    report_content += f"| {node_name} | {status_icon} {result['status']} | {throughput} | {latency_mean} | {success_rate}% | {duration}s |\\n"

            markdown_file = result_dir / "test_report.md"
            with open(markdown_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            self.logger.debug(f"Generated suite report: {markdown_file}")

        except Exception as e:
            self.logger.error(f"Failed to generate suite report: {e}")

    def generate_html_report(self, result_dir: Path, summary: Union[ResultSummary, TestSuiteResultSummary]):
        """ç”ŸæˆHTMLæŠ¥å‘Š - æ”¯æŒå•åœºæ™¯å’Œæµ‹è¯•å¥—ä»¶"""
        try:
            def safe_format(value, format_spec=''):
                if value is None:
                    return 'N/A'
                if format_spec:
                    return f"{value:{format_spec}}"
                return str(value)

            # æ£€æŸ¥summaryç±»å‹å¹¶ç”Ÿæˆç›¸åº”çš„HTMLæŠ¥å‘Š
            if isinstance(summary, TestSuiteResultSummary):
                # ç”Ÿæˆæµ‹è¯•å¥—ä»¶æ±‡æ€»HTMLæŠ¥å‘Š
                html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æµ‹è¯•å¥—ä»¶æŠ¥å‘Š - {summary.suite_name}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 20px; }}
        .metrics {{ display: flex; justify-content: space-around; margin: 20px 0; flex-wrap: wrap; }}
        .metric {{ text-align: center; padding: 15px; border: 1px solid #ddd; border-radius: 5px; margin: 5px; min-width: 150px; }}
        .metric h3 {{ margin: 0 0 10px 0; color: #333; }}
        .metric p {{ margin: 0; font-size: 1.2em; font-weight: bold; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .success {{ color: green; }}
        .error {{ color: red; }}
        .info-section {{ margin: 20px 0; }}
        .info-section h2 {{ color: #333; border-bottom: 2px solid #ddd; padding-bottom: 5px; }}
        .status-icon {{ font-size: 1.2em; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>æµ‹è¯•å¥—ä»¶æŠ¥å‘Š - {summary.suite_name}</h1>
        <p><strong>æµ‹è¯•æ—¶é—´:</strong> {summary.timestamp}</p>
        <p><strong>æ€»åœºæ™¯æ•°:</strong> {summary.total_scenarios}</p>
        <p><strong>æˆåŠŸåœºæ™¯æ•°:</strong> {summary.successful_scenarios}</p>
        <p><strong>å¤±è´¥åœºæ™¯æ•°:</strong> {summary.failed_scenarios}</p>
        <p><strong>æ€»ä½“æˆåŠŸç‡:</strong> {safe_format(summary.overall_success_rate_pct, '.1f')}%</p>
    </div>

    <div class="metrics">
        <div class="metric">
            <h3>æ€»ä½“å¹³å‡ååé‡</h3>
            <p>{safe_format(summary.overall_avg_throughput, '.2f')} tokens/s</p>
        </div>
        <div class="metric">
            <h3>æ€»ä½“æœ€å¤§ååé‡</h3>
            <p>{safe_format(summary.overall_max_throughput, '.2f')} tokens/s</p>
        </div>
        <div class="metric">
            <h3>æ€»æ‰§è¡Œæ—¶é—´</h3>
            <p>{safe_format(summary.total_execution_time, '.1f')} ç§’</p>
        </div>
        <div class="metric">
            <h3>æ€»ç»“æœæ–‡ä»¶æ•°</h3>
            <p>{summary.total_result_files}</p>
        </div>
        <div class="metric">
            <h3>æ€»æ–‡ä»¶å¤§å°</h3>
            <p>{safe_format(summary.total_size_mb, '.2f')} MB</p>
        </div>
    </div>

    <div class="info-section">
        <h2>å„åœºæ™¯è¯¦ç»†ç»“æœ</h2>
        <table>
            <tr>
                <th>åœºæ™¯åç§°</th>
                <th>çŠ¶æ€</th>
                <th>æ‰§è¡Œæ—¶é•¿(ç§’)</th>
                <th>ç»“æœæ–‡ä»¶æ•°</th>
                <th>æ–‡ä»¶å¤§å°(MB)</th>
                <th>æˆåŠŸèŠ‚ç‚¹</th>
                <th>å¤±è´¥èŠ‚ç‚¹</th>
                <th>é”™è¯¯ä¿¡æ¯</th>
            </tr>"""

                for scenario_name, scenario_info in summary.scenario_summaries.items():
                    status_icon = "âœ…" if scenario_info.get('status') == 'completed' else "âŒ"
                    status_class = "success" if scenario_info.get('status') == 'completed' else "error"
                    status = scenario_info.get('status', 'unknown')
                    duration = safe_format(scenario_info.get('duration_seconds', 0), '.1f')
                    result_files = scenario_info.get('result_files', 0)
                    result_size = safe_format(scenario_info.get('result_size_mb', 0), '.2f')
                    successful_nodes = scenario_info.get('successful_nodes', 0)
                    failed_nodes = scenario_info.get('failed_nodes', 0)
                    error_msg = scenario_info.get('error_message', '')[:50]  # æˆªæ–­é”™è¯¯ä¿¡æ¯
                    if len(scenario_info.get('error_message', '')) > 50:
                        error_msg += '...'

                    html_content += f"""
            <tr>
                <td>{scenario_name}</td>
                <td class="{status_class}"><span class="status-icon">{status_icon}</span> {status}</td>
                <td>{duration}</td>
                <td>{result_files}</td>
                <td>{result_size}</td>
                <td>{successful_nodes}</td>
                <td>{failed_nodes}</td>
                <td>{error_msg}</td>
            </tr>"""

                html_content += """
        </table>
    </div>"""

                # æ·»åŠ å¥åº·æ£€æŸ¥å’Œæ‰§è¡Œæ‘˜è¦ä¿¡æ¯
                if summary.health_report:
                    html_content += """
    <div class="info-section">
        <h2>å¥åº·æ£€æŸ¥æŠ¥å‘Š</h2>
        <table>
            <tr><th>æ£€æŸ¥é¡¹</th><th>çŠ¶æ€</th></tr>"""
                    for key, value in summary.health_report.items():
                        html_content += f"<tr><td>{key}</td><td>{value}</td></tr>"
                    html_content += "</table></div>"

                if summary.execution_summary:
                    html_content += """
    <div class="info-section">
        <h2>æ‰§è¡Œæ‘˜è¦</h2>
        <table>
            <tr><th>é¡¹ç›®</th><th>å€¼</th></tr>"""
                    for key, value in summary.execution_summary.items():
                        html_content += f"<tr><td>{key}</td><td>{value}</td></tr>"
                    html_content += "</table></div>"

                html_content += """
</body>
</html>"""

                # å¥—ä»¶æŠ¥å‘Šä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å
                html_file = result_dir / "suite_report.html"

            else:
                # åŸæœ‰çš„å•åœºæ™¯æŠ¥å‘Šé€»è¾‘ (ResultSummary)
                html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æµ‹è¯•ç»“æœæŠ¥å‘Š - {summary.scenario_name}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        .header {{ background-color: #f4f4f4; padding: 20px; border-radius: 5px; margin-bottom: 20px; }}
        .metrics {{ display: flex; justify-content: space-around; margin: 20px 0; flex-wrap: wrap; }}
        .metric {{ text-align: center; padding: 15px; border: 1px solid #ddd; border-radius: 5px; margin: 5px; min-width: 150px; }}
        .metric h3 {{ margin: 0 0 10px 0; color: #333; }}
        .metric p {{ margin: 0; font-size: 1.2em; font-weight: bold; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .success {{ color: green; }}
        .error {{ color: red; }}
        .status-icon {{ font-size: 1.2em; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>æµ‹è¯•ç»“æœæŠ¥å‘Š - {summary.scenario_name}</h1>
        <p><strong>æµ‹è¯•æ—¶é—´:</strong> {summary.timestamp}</p>
        <p><strong>æ€»èŠ‚ç‚¹æ•°:</strong> {summary.total_nodes}</p>
        <p><strong>æˆåŠŸèŠ‚ç‚¹æ•°:</strong> {summary.successful_nodes}</p>
        <p><strong>å¤±è´¥èŠ‚ç‚¹æ•°:</strong> {summary.failed_nodes}</p>
    </div>

    <div class="metrics">
        <div class="metric">
            <h3>å¹³å‡ååé‡</h3>
            <p>{safe_format(summary.avg_throughput, '.2f')} tokens/s</p>
        </div>
        <div class="metric">
            <h3>æœ€å¤§ååé‡</h3>
            <p>{safe_format(summary.max_throughput, '.2f')} tokens/s</p>
        </div>
        <div class="metric">
            <h3>æœ€å°ååé‡</h3>
            <p>{safe_format(summary.min_throughput, '.2f')} tokens/s</p>
        </div>
        <div class="metric">
            <h3>å¹³å‡å»¶è¿Ÿ</h3>
            <p>{safe_format(summary.avg_latency, '.3f')} s</p>
        </div>
        <div class="metric">
            <h3>æ€»è¯·æ±‚æ•°</h3>
            <p>{summary.total_requests}</p>
        </div>
        <div class="metric">
            <h3>æˆåŠŸè¯·æ±‚æ•°</h3>
            <p>{summary.total_successful_requests}</p>
        </div>
        <div class="metric">
            <h3>æ€»ä½“æˆåŠŸç‡</h3>
            <p>{safe_format(summary.overall_success_rate, '.1f')}%</p>
        </div>
        <div class="metric">
            <h3>ç»“æœæ–‡ä»¶æ•°</h3>
            <p>{summary.total_result_files}</p>
        </div>
        <div class="metric">
            <h3>æ€»æ–‡ä»¶å¤§å°</h3>
            <p>{safe_format(summary.total_size_mb, '.2f')} MB</p>
        </div>
    </div>

    <h2>èŠ‚ç‚¹è¯¦ç»†ç»“æœ</h2>
    <table>
        <tr>
            <th>èŠ‚ç‚¹åç§°</th>
            <th>çŠ¶æ€</th>
            <th>ååé‡</th>
            <th>å¹³å‡å»¶è¿Ÿ</th>
            <th>æˆåŠŸç‡</th>
            <th>æ‰§è¡Œæ—¶é•¿</th>
        </tr>"""

                for node_name, result in summary.node_results.items():
                    status_class = "success" if result.get('status') == 'completed' else "error"
                    status_icon = "âœ…" if result.get('status') == 'completed' else "âŒ"
                    status = result.get('status', 'unknown')
                    throughput = safe_format(result.get('throughput', 0), '.2f')
                    latency_mean = safe_format(result.get('latency_mean', 0), '.3f')
                    success_rate = safe_format(result.get('success_rate', 0), '.1f')
                    duration = safe_format(result.get('duration', 0), '.1f')

                    html_content += f"""
        <tr>
            <td>{node_name}</td>
            <td class="{status_class}"><span class="status-icon">{status_icon}</span> {status}</td>
            <td>{throughput}</td>
            <td>{latency_mean}</td>
            <td>{success_rate}%</td>
            <td>{duration}s</td>
        </tr>"""

                html_content += """
    </table>
</body>
</html>"""

                # å•åœºæ™¯æŠ¥å‘Šä½¿ç”¨åŸæœ‰æ–‡ä»¶å
                html_file = result_dir / "test_report.html"

            # å†™å…¥æ–‡ä»¶
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)

            self.logger.debug(f"Generated HTML report: {html_file}")

        except Exception as e:
            self.logger.error(f"Failed to generate HTML report: {e}")

    def generate_execution_overview_report(self, result_dir: Path, execution_data: dict):
        """
        ç”Ÿæˆæ€»ä½“æ‰§è¡Œæ¦‚è§ˆæŠ¥å‘Š - Markdownæ ¼å¼

        Args:
            result_dir: ç»“æœç›®å½•è·¯å¾„
            execution_data: æ‰§è¡Œæ•°æ®å­—å…¸ï¼ŒåŒ…å«execution_summaryã€health_reportã€test_suite_summaryå’Œvalidation_results
        """
        try:
            def safe_format(value, format_spec=''):
                if value is None:
                    return 'N/A'
                if format_spec:
                    return f"{value:{format_spec}}"
                return str(value)

            # ä»execution_dataä¸­æå–å„ä¸ªç»„ä»¶
            execution_summary = execution_data.get('execution_summary', {})
            health_report = execution_data.get('health_report', {})
            test_suite_summary = execution_data.get('test_suite_summary')
            validation_results = execution_data.get('validation_results', {})

            # æ„å»ºæŠ¥å‘Šå†…å®¹
            report_content = f"""# æµ‹è¯•å¥—ä»¶æ‰§è¡Œæ€»è§ˆæŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ” ç³»ç»Ÿå¥åº·æ£€æŸ¥

"""

            # å¥åº·æ£€æŸ¥ä¿¡æ¯
            if health_report:
                # æ€»ä½“çŠ¶æ€
                overall_status = health_report.get('overall_status', 'unknown')
                overall_icon = "âœ…" if overall_status in ['healthy', 'æ­£å¸¸', 'ok'] else "âŒ"
                report_content += f"- {overall_icon} **æ€»ä½“çŠ¶æ€**: {overall_status}\n"

                # æ£€æŸ¥æ—¶é—´
                check_time = health_report.get('check_time', 'N/A')
                if check_time != 'N/A':
                    # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                    try:
                        if 'T' in str(check_time):
                            dt = datetime.fromisoformat(str(check_time).replace('Z', '+00:00'))
                            formatted_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                        else:
                            formatted_time = str(check_time)
                    except:
                        formatted_time = str(check_time)
                    report_content += f"- ğŸ• **æ£€æŸ¥æ—¶é—´**: {formatted_time}\n"

                # ç»„ä»¶çŠ¶æ€
                components = health_report.get('components', {})
                if components:
                    report_content += f"- ğŸ“Š **ç»„ä»¶æ£€æŸ¥** ({len(components)} ä¸ªç»„ä»¶):\n"
                    for comp_name, comp_info in components.items():
                        if isinstance(comp_info, dict):
                            comp_status = comp_info.get('status', 'unknown')
                            comp_icon = "âœ…" if comp_status in ['healthy', 'æ­£å¸¸', 'ok'] else "âŒ"
                            report_content += f"  - {comp_icon} **{comp_name}**: {comp_status}\n"
                        else:
                            comp_icon = "âœ…" if comp_info in ['healthy', 'æ­£å¸¸', 'ok', True] else "âŒ"
                            report_content += f"  - {comp_icon} **{comp_name}**: {comp_info}\n"

                # ç»Ÿè®¡æ‘˜è¦
                summary = health_report.get('summary', {})
                if summary and isinstance(summary, dict):
                    report_content += "- ğŸ“ˆ **çŠ¶æ€ç»Ÿè®¡**: "
                    status_parts = []
                    for status, count in summary.items():
                        if count > 0:
                            status_icon = "âœ…" if status == 'healthy' else ("âš ï¸" if status == 'degraded' else "âŒ")
                            status_parts.append(f"{status_icon} {status}: {count}")
                    report_content += ", ".join(status_parts) + "\n"

                # å…³é”®é—®é¢˜
                critical_issues = health_report.get('critical_issues', [])
                if critical_issues:
                    report_content += f"- âš ï¸ **å…³é”®é—®é¢˜**: {len(critical_issues)} ä¸ªé—®é¢˜\n"
                    for issue in critical_issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé—®é¢˜
                        report_content += f"  - {issue}\n"
                    if len(critical_issues) > 3:
                        report_content += f"  - ... è¿˜æœ‰ {len(critical_issues) - 3} ä¸ªé—®é¢˜\n"
                else:
                    report_content += "- âœ… **å…³é”®é—®é¢˜**: æ— \n"
            else:
                report_content += "- âš ï¸ å¥åº·æ£€æŸ¥ä¿¡æ¯ä¸å¯ç”¨\n"


            # éªŒè¯ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if validation_results:
                report_content += f"""
## âœ… é…ç½®éªŒè¯ç»“æœ

"""
                for node_name, node_data in validation_results.items():
                    # èŠ‚ç‚¹æ€»ä½“çŠ¶æ€
                    if isinstance(node_data, dict):
                        overall_status = node_data.get('overall_status', 'unknown')
                        checks = node_data.get('checks', {})

                        # èŠ‚ç‚¹çŠ¶æ€å›¾æ ‡
                        node_icon = "âœ…" if overall_status in ['ready', 'passed', 'healthy'] else "âŒ"
                        report_content += f"- {node_icon} **{node_name}**: {overall_status} ({len(checks)} é¡¹æ£€æŸ¥)\n"

                        # è¯¦ç»†æ£€æŸ¥ç»“æœ
                        for check_name, check_data in checks.items():
                            if isinstance(check_data, dict):
                                check_status = check_data.get('status', 'unknown')
                                check_output = check_data.get('output', '')

                                # æ£€æŸ¥é¡¹å›¾æ ‡
                                check_icon = "âœ…" if check_status == 'passed' else "âŒ"

                                # æå–å…³é”®ä¿¡æ¯
                                formatted_info = self._extract_check_info(check_name, check_output)
                                report_content += f"  - {check_icon} **{self._format_check_name(check_name)}**: {formatted_info}\n"
                    else:
                        # ç®€å•å€¼çš„æƒ…å†µï¼ˆå‘åå…¼å®¹ï¼‰
                        icon = "âœ…" if node_data in ['é€šè¿‡', 'passed', True] else "âŒ"
                        report_content += f"- {icon} **{node_name}**: {node_data}\n"


            # æµ‹è¯•å¥—ä»¶ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if test_suite_summary:
                report_content += f"""
## ğŸ“Š æµ‹è¯•å¥—ä»¶ç»“æœæ±‡æ€»

### åŸºæœ¬ç»Ÿè®¡
- **æ€»åœºæ™¯æ•°**: {safe_format(test_suite_summary.total_scenarios)}
- **æˆåŠŸåœºæ™¯æ•°**: {safe_format(test_suite_summary.successful_scenarios)}
- **å¤±è´¥åœºæ™¯æ•°**: {safe_format(test_suite_summary.failed_scenarios)}
- **æ€»ä½“æˆåŠŸç‡**: {safe_format(test_suite_summary.overall_success_rate, '.1f')}%
- **æ€»æ‰§è¡Œæ—¶é—´**: {safe_format(test_suite_summary.total_execution_time, '.1f')} ç§’

### æ€§èƒ½æŒ‡æ ‡
- **æ€»ä½“å¹³å‡ååé‡**: {safe_format(test_suite_summary.overall_avg_throughput, '.2f')} tokens/s
- **æ€»ä½“æœ€å¤§ååé‡**: {safe_format(test_suite_summary.overall_max_throughput, '.2f')} tokens/s

### æ–‡ä»¶ç»Ÿè®¡
- **æ€»ç»“æœæ–‡ä»¶æ•°**: {safe_format(test_suite_summary.total_result_files)}
- **æ€»æ–‡ä»¶å¤§å°**: {safe_format(test_suite_summary.total_size_mb, '.2f')} MB

### å„åœºæ™¯è¯¦ç»†ç»“æœ

| åœºæ™¯åç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é•¿(ç§’) | ç»“æœæ–‡ä»¶æ•° | æ–‡ä»¶å¤§å°(MB) | æˆåŠŸèŠ‚ç‚¹ | å¤±è´¥èŠ‚ç‚¹ | é”™è¯¯ä¿¡æ¯ |
|---------|------|-------------|------------|-------------|----------|----------|----------|
"""

                # æ·»åŠ å„åœºæ™¯çš„è¯¦ç»†ä¿¡æ¯
                for scenario_name, scenario_info in test_suite_summary.scenario_summaries.items():
                    status_icon = "âœ…" if scenario_info.get('status') == 'completed' else "âŒ"
                    status = scenario_info.get('status', 'unknown')
                    duration = safe_format(scenario_info.get('duration_seconds', 0), '.1f')
                    result_files = scenario_info.get('result_files', 0)
                    result_size = safe_format(scenario_info.get('result_size_mb', 0), '.2f')
                    successful_nodes = scenario_info.get('successful_nodes', 0)
                    failed_nodes = scenario_info.get('failed_nodes', 0)
                    error_msg = scenario_info.get('error_message', '')[:50]  # æˆªæ–­é”™è¯¯ä¿¡æ¯
                    if len(scenario_info.get('error_message', '')) > 50:
                        error_msg += '...'

                    report_content += f"| {scenario_name} | {status_icon} {status} | {duration} | {result_files} | {result_size} | {successful_nodes} | {failed_nodes} | {error_msg} |\n"


            # æ·»åŠ é¡µè„šä¿¡æ¯
            report_content += f"""
---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æŠ¥å‘Šç‰ˆæœ¬**: v2.0
**ç³»ç»Ÿ**: Playbook åˆ†å¸ƒå¼æµ‹è¯•ç³»ç»Ÿ
"""

            # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
            report_file = result_dir / "run-all-suite.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            self.logger.info(f"Generated execution overview report: {report_file}")

        except Exception as e:
            self.logger.error(f"Failed to generate execution overview report: {e}")
            raise

    def _format_check_name(self, check_name: str) -> str:
        """æ ¼å¼åŒ–æ£€æŸ¥é¡¹åç§°ä¸ºç”¨æˆ·å‹å¥½çš„æ˜¾ç¤º"""
        name_mapping = {
            'docker_version': 'Dockerç‰ˆæœ¬',
            'gpu_info': 'GPUèµ„æº',
            'disk_space': 'ç£ç›˜ç©ºé—´',
            'memory_info': 'å†…å­˜ä¿¡æ¯',
            'benchmark_image': 'é•œåƒæ£€æŸ¥',
            'docker_compose_version_node1': 'Docker Compose (node1)',
            'docker_compose_version_node2': 'Docker Compose (node2)',
            'docker_compose_version': 'Docker Compose'
        }
        return name_mapping.get(check_name, check_name.replace('_', ' ').title())

    def _extract_check_info(self, check_name: str, check_output: str) -> str:
        """ä»æ£€æŸ¥è¾“å‡ºä¸­æå–å…³é”®ä¿¡æ¯"""
        if not check_output:
            return "æ— è¾“å‡º"

        # Dockerç‰ˆæœ¬
        if check_name == 'docker_version':
            import re
            match = re.search(r'Docker version (\S+)', check_output)
            return match.group(1) if match else check_output.strip()

        # GPUä¿¡æ¯
        elif check_name == 'gpu_info':
            lines = check_output.strip().split('\n')
            gpu_count = len([line for line in lines if 'NVIDIA' in line])
            if gpu_count > 0:
                # æå–GPUå‹å·å’Œå†…å­˜
                first_gpu = lines[0] if lines else ''
                parts = first_gpu.split(', ')
                if len(parts) >= 2:
                    gpu_model = parts[0].replace('NVIDIA ', '')
                    try:
                        gpu_memory_mb = int(parts[1])
                        gpu_memory = f"{gpu_memory_mb // 1024}GB"
                    except ValueError:
                        gpu_memory = parts[1]
                    return f"{gpu_count}x {gpu_model} ({gpu_memory})"
            return f"{gpu_count} GPU(s)"

        # ç£ç›˜ç©ºé—´
        elif check_name == 'disk_space':
            import re
            # è§£æ df è¾“å‡º
            match = re.search(r'(\S+)\s+(\S+)\s+(\S+)\s+(\S+)\s+(\d+)%', check_output)
            if match:
                size = match.group(2)
                used = match.group(3)
                usage = match.group(5)
                return f"{size} æ€»å®¹é‡ ({usage}% ä½¿ç”¨)"
            return "ç£ç›˜ä¿¡æ¯å¯ç”¨"

        # å†…å­˜ä¿¡æ¯
        elif check_name == 'memory_info':
            import re
            # è§£æ free å‘½ä»¤è¾“å‡º
            match = re.search(r'Mem:\s+(\S+)\s+(\S+)\s+(\S+)', check_output)
            if match:
                total = match.group(1)
                used = match.group(2)
                free = match.group(3)
                return f"æ€»è®¡ {total}, å¯ç”¨ {free}"
            return "å†…å­˜ä¿¡æ¯å¯ç”¨"

        # Docker Composeç‰ˆæœ¬
        elif 'docker_compose_version' in check_name:
            import re
            match = re.search(r'version (\S+)', check_output)
            return match.group(1) if match else check_output.strip()

        # é•œåƒæ£€æŸ¥
        elif check_name == 'benchmark_image':
            if 'not found' in check_output.lower():
                return "é•œåƒä¸å­˜åœ¨ï¼ˆæ­£å¸¸ï¼‰"
            return check_output.strip()

        # é»˜è®¤æƒ…å†µ
        else:
            # æˆªæ–­è¿‡é•¿çš„è¾“å‡º
            output = check_output.strip()
            if len(output) > 50:
                return output[:50] + "..."
            return output

    def archive_results(self, result_dir: str, archive_name: Optional[str] = None) -> str:
        """
        å½’æ¡£ç»“æœç›®å½•

        Args:
            result_dir: ç»“æœç›®å½•è·¯å¾„
            archive_name: å½’æ¡£æ–‡ä»¶å

        Returns:
            å½’æ¡£æ–‡ä»¶è·¯å¾„
        """
        result_path = Path(result_dir)
        if not result_path.exists():
            raise ValueError(f"Result directory does not exist: {result_dir}")

        if not archive_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            archive_name = f"{result_path.name}_{timestamp}.tar.gz"

        archive_path = result_path.parent / archive_name

        self.logger.info(f"Archiving results: {result_dir} -> {archive_path}")

        with tarfile.open(archive_path, 'w:gz') as tar:
            tar.add(result_path, arcname=result_path.name)

        self.logger.info(f"Results archived to: {archive_path}")
        return str(archive_path)